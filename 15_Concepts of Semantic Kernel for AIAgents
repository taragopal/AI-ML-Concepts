
Semantic Kernel (SK) is a lightweight, open-source SDK from Microsoft that acts as an orchestration layer for connecting Large Language Models (LLMs) with your existing code and data. Think of it as the central nervous system for your AI applications. It helps you build intelligent AI agents or "copilots" that can reason, plan, and take action by using both the "semantic" (AI) and "native" (code) functions you provide.

LAB.AI102.2.6: Develop an Azure AI agent with the Semantic Kernel SDK: https://microsoftlearning.github.io/mslearn-ai-agents/Instructions/04-semantic-kernel.html

The Analogy
-------------
Imagine you are a CEO (the LLM) who is very good at thinking and making high-level decisions but can't perform mundane tasks like sending an email or booking a flight. To do these things, you have a team of highly specialized assistants (the plugins). One assistant is an email specialist (a native function), another is a travel agent (an OpenAPI function calling an external API), and a third is a data analyst (a semantic function that can summarize information).

When a user asks you (the LLM) to "book a flight to London and send a confirmation email," you don't do the tasks yourself. Instead, you figure out which assistants are needed for the job and give them instructions. The travel agent books the flight, and the email specialist sends the confirmation. The Semantic Kernel is like the CEO's executive assistant, who knows all the specialized assistants, what they can do, and how to chain their tasks together to complete a complex request.

Key Concepts to Memorize
-------------------------
I. The Kernel: The central object that orchestrates everything. It's the brain of your AI application, managing services, plugins, and memory.
II. Plugins (Skills): Collections of functions that extend the LLM's capabilities. These are the specialized "assistants" the LLM can call upon. They can be:
III. Native Functions: Your existing code written in C#, Python, or Java. You describe what the code does, and the AI can call it.
IV. Semantic Functions: Prompts that define a specific task for the LLM, like "Summarize this text" or "Generate a poem."
V. Planners: The part of the Kernel that helps the LLM automatically chain functions together to accomplish a multi-step goal.
VI. Memory: Provides the LLM with both short-term context (the current conversation) and long-term knowledge (data retrieved from a vector database).


Azure AI specific core components: 
----------------------------------
AI service connectors - connect the code to AI services from different providers under a common interface. Supported services include Chat Completion, Text Generation, and more.
Memory connectors - expose vector stores from other providers under a common interface.
Functions and plugins - containers for functions that are registered with the kernel. Once registered, functions can be invoked by the AI or through prompt templates.
Prompt templates - combine instructions, user input, and function outputs into a reusable format. Prompt templates allow AI models to execute predefined steps dynamically.
Filters - allow custom actions to be performed before and after a function or prompt is invoked. When registered, function filters act as outer layers and prompt filters as inner layers.


Agent framework components
-----------------------------
The Agent Framework within Semantic Kernel helps streamline the creation of agents and enables multi-agent collaboration in conversations while integrating human input. The framework supports different types of agents, including ChatCompletionAgent, OpenAIAssistantAgent, and AzureAIAgent.

What is an Azure AI Agent?
---------------------------
The AzureAIAgent class provides a seamless way to build and interact with AI agents using the Foundry Agent Service. It abstracts the complexity of managing AI agents by offering a more structured and intuitive interface within the Semantic Kernel Agent Framework. Key benefits include:
Simplified agent creation – The AzureAIAgent class allows developers to define AI agents with minimal configuration, leveraging the power of Foundry Agent Service without managing the underlying infrastructure.
Automatic tool invocation – The agent can automatically call and execute tools, integrating seamlessly with Azure AI Search, Bing, Azure Functions, and more.
Thread and conversation management – Provides built-in mechanisms for managing conversation states, ensuring smooth multi-agent interactions.
Secure enterprise integration – Enables secure and compliant AI agent development with keyless authentication and customizable storage options.
By using the AzureAIAgent class, developers can take full advantage of Foundry Agent Service while taking advantage of the features offered by the Semantic Kernel SDK. This allows for robust AI-driven workflows that scale efficiently across enterprise applications.


Creating an AzureAIAgent
-----------------------------
An AzureAIAgent object encapsulates all the core capabilities you typically use the Kernel for, like function execution, planning, and memory access. This object acts as a self-contained agent runtime.

To use an AzureAIAgent:
------------------------------
Create an Azure AI Foundry project.
Add the project connection string to your Semantic Kernel application code.
Create an AzureAIAgentSettings object.
Create an AzureAIAgent client.
Create an agent definition on the agent service provided by the client.
Create an agent based on the definition.

Here's the code that illustrates how to create an AzureAIAgent:
--------------------------------------------------------------------

from azure.identity.aio import DefaultAzureCredential
from semantic_kernel.agents import AzureAIAgent, AzureAIAgentThread, AzureAIAgentSettings

# Create an AzureAIAgentSettings object
ai_agent_settings = AzureAIAgentSettings()

# Create an AzureAIAgent client
async with (@
    DefaultAzureCredential() as creds,
    AzureAIAgent.create_client(credential=creds) as client,
):
    # Create an agent definition on the agent service provided by the client
    agent_definition = await client.agents.create_agent(
        model=ai_agent_settings.model_deployment_name,
        name="<name>",
        instructions="<instructions>",
    )

    # Create the AI agent based on the agent definition
    agent = AzureAIAgent(
        client=client,
        definition=agent_definition,
    )



# Once your agent is defined, you can create a thread to interact with your agent and invoke responses for inputs. For example:

# Create the agent thread
thread: AzureAIAgentThread = AzureAIAgentThread(client=client)

try:
    # Create prompts 
    prompt_messages = ["What are the largest semiconductor manufacturing companies?"]

    # Invoke a response from the agent
    response = await agent.get_response(messages=prompt_messages, thread_id=thread.id)

    # View the response
    print(response)
finally:
    # Clean up the thread
    await thread.delete() if thread else None


How to use plugins with AzureAIAgent
----------------------------------------
Define your plugin : You can create a plugin by defining a class and annotating its methods with the kernel_function decorator. The decorator lets Semantic Kernel know that this function can be called by the AI or referenced in a prompt. The kernel_function decorator also supports a description attribute to help the AI understand how to use the function.

Add the plugin to your agent: Once you define your plugin, you can add it to your AzureAIAgent by creating a new instance of the plugin and adding it to the agent's plugin collection.

Invoke the plugin's functions: You can invoke your plugin's functions by using prompts on your agent's message thread. For example, if you have a plugin function called get_tasks, your prompt to the agent might be "What tasks do I have?".


The Why and How
----------------
Why use Semantic Kernel? It allows developers to build more than just simple chatbots. It's about creating agents—autonomous systems that can reason and perform complex tasks.

How it works:
-------------
Orchestration: Semantic Kernel acts as an orchestrator. A user's prompt comes in, and the kernel determines the intent.

Planning: Using a planner, the kernel can create a step-by-step plan to fulfill the request. For example, if a user says, "Tell me about the latest sales numbers and create a report," the planner might:

Step 1: Use a "sales data retrieval" native function to get data from a database.

Step 2: Use a "summarize data" semantic function to create a concise summary.

Step 3: Use a "generate report" semantic function to format the information.

Execution: The kernel executes the plan, dynamically calling the appropriate semantic and native functions. It can also handle the handoff between different agents in a multi-agent system, ensuring seamless collaboration.

Practical Implementation in Modern Cloud-First Enterprises
--------------------------------------------------------------
Semantic Kernel on Azure is powerful because it allows you to connect your existing enterprise data and code with cutting-edge AI services like Azure OpenAI Service. This is a game-changer for building "copilot" experiences that are deeply integrated with your business.


Project Ideas:
----------------------
(1)
Enterprise Copilot for IT Support:
Idea: A copilot that automates help desk tasks.
Implementation: Create plugins for common IT tasks.

Native Function Plugin: ResetUserPassword(username) that calls an internal API.

Semantic Function Plugin: DiagnoseProblem(ticketDescription) that uses an LLM to analyze the user's issue and suggest solutions.

Long-Term Memory: Connect to a knowledge base of past tickets and resolutions using Azure AI Search to enable Retrieval-Augmented Generation (RAG). This allows the copilot to find similar past issues and their solutions.
(2)
Marketing Content Automation:
Idea: An agent that generates personalized marketing content based on customer data.
Implementation: Native Function Plugin: GetCustomerProfile(customerId) to retrieve customer data from a CRM.

Semantic Function Plugin: GeneratePersonalizedEmail(customerProfile) to create a customized email draft.

Planner: The agent could be instructed to "send a personalized follow-up email to all customers who viewed the new product page but didn't buy." The planner would use the native function to get each customer's profile and then the semantic function to generate the email content.

(3)
Financial Document Analysis:
Idea: An AI agent that analyzes financial reports and extracts key information for reporting.
Implementation:Native Function Plugin: A plugin that uses a service like Azure AI Document Intelligence to OCR and parse PDF reports.

Semantic Function Plugin: ExtractKeyMetrics(reportContent) to pull out numbers like revenue and profit.

Long-Term Memory: Store the extracted metrics in a structured database or an Azure AI Search index for easy retrieval and querying.

Semantic Kernel provides a robust, enterprise-ready framework to build these types of sophisticated, real-world AI applications that go far beyond simple question-answering.
